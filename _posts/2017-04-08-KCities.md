---
layout: post
title: "A Tale of K Cities"
categories: [nyc, data]
---

Here's a little project I did running clustering algorithms on New York City neighborhoods. Anybody who lives in the five boroughs knows certain neighborhoods are more like others, whether for cultural, economic, or other reasons. I fed a bunch of sociological and economic data from the 2010 Census into a K-means clustering algorithm and asked it to identify three distinct typesÂ of neighborhoods in the city. What makes this interesting is I didn't feed the model any underlying structure (this is unsupervised learning). Nevertheless, the results match a lot of my qualitative priors established from living in NYC for the past eight years. So what do I think the clustering algorithm found?

* **Cluster 1**: Manhattan south of 110th Street and Downtown Brooklyn, AKA " The Tourist Guide to NYC" or "Starbucks and Duane Reade on every corner."
* **Cluster 2**: Low-to-middle income neighborhoods in the boroughs (and Lower East Side in Manhattan), usually with high minority and foreign-born populations. Also the center of ongoing gentrification.  
* **Cluster 3**:  Staten Island + other working-middle class neighborhoods in the far boroughs. This is where you may find people saying "fugheddaboudit" out loud.

<iframe width="100%" height="520" frameborder="0" src="https://srimmele.carto.com/viz/8daedcd2-1c96-11e7-b055-0e05a8b3e3d7/embed_map" allowfullscreen webkitallowfullscreen mozallowfullscreen oallowfullscreen msallowfullscreen></iframe>

What's the conclusion here? I was struck by how a simple algorithm with relatively little data was able to find underlying structure. Of course, that structure was meaningless without outside human interpretation - which is in turn subjective and fallible. So by all means, let your machines learn. But do remember to interpret what they tell you!
